{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [106] at entry 0 and [103] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     39\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     42\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    204\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[0;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [106] at entry 0 and [103] at entry 1"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class MarketingDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tokenizer.encode(self.lines[idx], add_special_tokens=True))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MarketingDataset('text.txt', tokenizer)\n",
    "valid_dataset = MarketingDataset('valid.txt', tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(3):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch, labels=batch)\n",
    "        loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "            valid_loss += loss.item() * batch.size(0)\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review keywords: ['food', 'was', 'delicious', 'but', 'service', 'was', 'slow']\n",
      "Best match in response: food\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_keywords(review):\n",
    "    # Define a list of common stop words to exclude from keywords\n",
    "    stop_words = ['the', 'and', 'is', 'in', 'it', 'this', 'that']\n",
    "    \n",
    "    # Split the review into individual words\n",
    "    words = re.findall(r'\\w+', review.lower())\n",
    "    \n",
    "    # Filter out stop words and return the remaining keywords\n",
    "    keywords = [word for word in words if word not in stop_words]\n",
    "    return keywords\n",
    "\n",
    "def find_best_match(review_keywords, response):\n",
    "    # Initialize variables to store the best match and its score\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    # Extract keywords from the response\n",
    "    response_keywords = extract_keywords(response)\n",
    "    \n",
    "    # Iterate over each keyword in the review\n",
    "    for keyword in review_keywords:\n",
    "        # Calculate the score for the keyword based on its presence in the response\n",
    "        score = sum(keyword in word for word in response_keywords)\n",
    "        \n",
    "        # Check if the current score is higher than the previous best score\n",
    "        if score > best_score:\n",
    "            best_match = keyword\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match\n",
    "\n",
    "# Example usage\n",
    "review = \"The food was delicious, but the service was slow.\"\n",
    "response = \"We apologize for the slow service. Our chef takes great pride in preparing delicious food.\"\n",
    "\n",
    "review_keywords = extract_keywords(review)\n",
    "best_match = find_best_match(review_keywords, response)\n",
    "\n",
    "print(\"Review keywords:\", review_keywords)\n",
    "print(\"Best match in response:\", best_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (4.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (2.0.1)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Using cached torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: click in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torchvision->sentence-transformers) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: torchvision, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)b421b/.gitattributes: 100%|██████████| 491/491 [00:00<00:00, 81.7kB/s]\n",
      "Downloading (…)b4891cdb421b/LICENSE: 100%|██████████| 11.4k/11.4k [00:00<00:00, 1.42MB/s]\n",
      "Downloading (…)891cdb421b/README.md: 100%|██████████| 10.5k/10.5k [00:00<00:00, 1.05MB/s]\n",
      "Downloading (…)1cdb421b/config.json: 100%|██████████| 570/570 [00:00<00:00, 47.6kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 440M/440M [06:08<00:00, 1.19MB/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [06:21<00:00, 1.16MB/s] \n",
      "Downloading (…)b421b/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 794kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 2.33kB/s]\n",
      "Downloading (…)891cdb421b/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 518kB/s]\n",
      "No sentence-transformers model found with name C:\\Users\\91932/.cache\\torch\\sentence_transformers\\bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\91932/.cache\\torch\\sentence_transformers\\bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: The food was delicious, but the service was slow.\n",
      "Best Response: We apologize for the slow service. Our chef takes great pride in preparing delicious food.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def calculate_similarity(review, responses):\n",
    "    # Load pre-trained BERT model\n",
    "    model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "    # Encode the review and responses into fixed-length embeddings\n",
    "    review_embedding = model.encode([review])[0]\n",
    "    response_embeddings = model.encode(responses)\n",
    "\n",
    "    # Calculate cosine similarity between the review and each response\n",
    "    similarity_scores = np.dot(response_embeddings, review_embedding) / (np.linalg.norm(response_embeddings, axis=1) * np.linalg.norm(review_embedding))\n",
    "\n",
    "    # Find the index of the response with the highest similarity score\n",
    "    best_match_index = np.argmax(similarity_scores)\n",
    "\n",
    "    return responses[best_match_index]\n",
    "\n",
    "# Example usage\n",
    "review = \"The food was delicious, but the service was slow.\"\n",
    "responses = [\n",
    "    \"We apologize for the slow service. Our chef takes great pride in preparing delicious food.\",\n",
    "    \"Thank you for your feedback. We will address the issue with our service staff.\",\n",
    "    \"We are glad you enjoyed the food. We'll work on improving the service speed.\",\n",
    "]\n",
    "\n",
    "best_response = calculate_similarity(review, responses)\n",
    "\n",
    "print(\"Review:\", review)\n",
    "print(\"Best Response:\", best_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad_sequence(): argument 'padding_value' (position 3) must be float, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     46\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 48\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     49\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollate_fn\u001b[39m(batch):\n\u001b[0;32m     31\u001b[0m     input_ids \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor(item) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m---> 32\u001b[0m     padded_input_ids \u001b[39m=\u001b[39m pad_sequence(input_ids, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, padding_value\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad_token_id)\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m padded_input_ids\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\utils\\rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    395\u001b[0m         sequences \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39munbind(\u001b[39m0\u001b[39m)\n\u001b[0;32m    397\u001b[0m \u001b[39m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mpad_sequence(sequences, batch_first, padding_value)\n",
      "\u001b[1;31mTypeError\u001b[0m: pad_sequence(): argument 'padding_value' (position 3) must be float, not NoneType"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MarketingDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenizer.encode(self.lines[idx], add_special_tokens=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MarketingDataset('text.txt', tokenizer)\n",
    "valid_dataset = MarketingDataset('valid.txt', tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item) for item in batch]\n",
    "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    return padded_input_ids\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch, labels=batch)\n",
    "        loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "            valid_loss += loss.item() * batch.size(0)\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad_sequence(): argument 'padding_value' (position 3) must be float, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     46\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m---> 48\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     49\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "Cell \u001b[1;32mIn[3], line 32\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollate_fn\u001b[39m(batch):\n\u001b[0;32m     31\u001b[0m     input_ids \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor(item) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m---> 32\u001b[0m     padded_input_ids \u001b[39m=\u001b[39m pad_sequence(input_ids, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, padding_value\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49mpad_token_id)\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m padded_input_ids\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\utils\\rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[1;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[0;32m    395\u001b[0m         sequences \u001b[39m=\u001b[39m sequences\u001b[39m.\u001b[39munbind(\u001b[39m0\u001b[39m)\n\u001b[0;32m    397\u001b[0m \u001b[39m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[39m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mpad_sequence(sequences, batch_first, padding_value)\n",
      "\u001b[1;31mTypeError\u001b[0m: pad_sequence(): argument 'padding_value' (position 3) must be float, not NoneType"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MarketingDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenizer.encode(self.lines[idx], add_special_tokens=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MarketingDataset('text.txt', tokenizer)\n",
    "valid_dataset = MarketingDataset('valid.txt', tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item) for item in batch]\n",
    "    padded_input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    return padded_input_ids\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch, labels=batch)\n",
    "        loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "            valid_loss += loss.item() * batch.size(0)\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class MarketingDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenizer.encode(self.lines[idx], add_special_tokens=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MarketingDataset('text.txt', tokenizer)\n",
    "valid_dataset = MarketingDataset('valid.txt', tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item) for item in batch]\n",
    "    max_len = max(len(ids) for ids in input_ids)\n",
    "    padded_input_ids = torch.stack([torch.cat((ids, torch.zeros(max_len - len(ids), dtype=torch.long))) for ids in input_ids])\n",
    "    return padded_input_ids\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch, labels=batch)\n",
    "        loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "            valid_loss += loss.item() * batch.size(0)\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Train Loss: 0.0156\n",
      "Valid Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "print(f\"Train Loss: {train_loss:.4f}\")\n",
    "print(f\"Valid Loss: {valid_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class MarketingDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenizer.encode(self.lines[idx], add_special_tokens=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MarketingDataset('text.txt', tokenizer)\n",
    "valid_dataset = MarketingDataset('valid.txt', tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item) for item in batch]\n",
    "    max_len = max(len(ids) for ids in input_ids)\n",
    "    padded_input_ids = torch.stack([torch.cat((ids, torch.zeros(max_len - len(ids), dtype=torch.long))) for ids in input_ids])\n",
    "    return padded_input_ids\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch, labels=batch)\n",
    "        loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "            valid_loss += loss.item() * batch.size(0)\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        \n",
    "    perplexity = torch.exp(torch.tensor(valid_loss))\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model2.pt')\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# Load the pre-trained GPT-3 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Load the pre-trained GPT-3 model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Load the text dataset\n",
    "dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path='inputs.txt',\n",
    "    block_size=512\n",
    ")\n",
    "\n",
    "# Create a data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, num_samples=10)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=32,\n",
    "    learning_rate=5e-5,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "# Define the trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Fine-tune the language model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model('./best_model3.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlibNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading matplotlib-3.7.1-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "                                              0.0/7.6 MB ? eta -:--:--\n",
      "                                              0.0/7.6 MB ? eta -:--:--\n",
      "                                              0.0/7.6 MB ? eta -:--:--\n",
      "                                              0.1/7.6 MB 751.6 kB/s eta 0:00:11\n",
      "                                              0.1/7.6 MB 751.6 kB/s eta 0:00:11\n",
      "     -                                        0.2/7.6 MB 787.7 kB/s eta 0:00:10\n",
      "     -                                        0.2/7.6 MB 919.0 kB/s eta 0:00:09\n",
      "     -                                        0.3/7.6 MB 886.2 kB/s eta 0:00:09\n",
      "     -                                        0.4/7.6 MB 1.0 MB/s eta 0:00:08\n",
      "     --                                       0.4/7.6 MB 933.2 kB/s eta 0:00:08\n",
      "     --                                       0.5/7.6 MB 1.1 MB/s eta 0:00:07\n",
      "     --                                       0.5/7.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ---                                      0.6/7.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ---                                      0.6/7.6 MB 1.1 MB/s eta 0:00:07\n",
      "     ----                                     0.8/7.6 MB 1.2 MB/s eta 0:00:06\n",
      "     ----                                     0.8/7.6 MB 1.2 MB/s eta 0:00:06\n",
      "     ----                                     0.9/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     -----                                    1.0/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     -----                                    1.1/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     -----                                    1.1/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     -----                                    1.1/7.6 MB 1.2 MB/s eta 0:00:06\n",
      "     ------                                   1.3/7.6 MB 1.3 MB/s eta 0:00:05\n",
      "     ------                                   1.3/7.6 MB 1.3 MB/s eta 0:00:05\n",
      "     -------                                  1.5/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     -------                                  1.5/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     --------                                 1.6/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     --------                                 1.6/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------                                1.7/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------                                1.8/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     ----------                               1.9/7.6 MB 1.4 MB/s eta 0:00:05\n",
      "     ----------                               2.0/7.6 MB 1.5 MB/s eta 0:00:04\n",
      "     ----------                               2.0/7.6 MB 1.4 MB/s eta 0:00:04\n",
      "     -----------                              2.2/7.6 MB 1.5 MB/s eta 0:00:04\n",
      "     -----------                              2.2/7.6 MB 1.5 MB/s eta 0:00:04\n",
      "     ------------                             2.4/7.6 MB 1.6 MB/s eta 0:00:04\n",
      "     ------------                             2.4/7.6 MB 1.6 MB/s eta 0:00:04\n",
      "     -------------                            2.5/7.6 MB 1.5 MB/s eta 0:00:04\n",
      "     -------------                            2.7/7.6 MB 1.6 MB/s eta 0:00:04\n",
      "     --------------                           2.8/7.6 MB 1.6 MB/s eta 0:00:04\n",
      "     --------------                           2.8/7.6 MB 1.6 MB/s eta 0:00:03\n",
      "     ---------------                          2.9/7.6 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------------                         3.1/7.6 MB 1.6 MB/s eta 0:00:03\n",
      "     ----------------                         3.2/7.6 MB 1.6 MB/s eta 0:00:03\n",
      "     -----------------                        3.4/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     -----------------                        3.4/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------                       3.5/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     ------------------                       3.5/7.6 MB 1.6 MB/s eta 0:00:03\n",
      "     -------------------                      3.7/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     -------------------                      3.7/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------                     3.9/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------                     3.9/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------------                    4.1/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     ---------------------                    4.1/7.6 MB 1.7 MB/s eta 0:00:03\n",
      "     ----------------------                   4.2/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------                   4.4/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     -----------------------                  4.4/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     -----------------------                  4.6/7.6 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 4.6/7.6 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 4.7/7.6 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 4.7/7.6 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 4.8/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------                 4.8/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------                 4.8/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     ------------------------                 4.8/7.6 MB 1.7 MB/s eta 0:00:02\n",
      "     -------------------------                4.9/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     -------------------------                4.9/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     -------------------------                5.0/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------------               5.0/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------------               5.0/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------------               5.1/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------------               5.1/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------------              5.2/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------------              5.2/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------------              5.3/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ---------------------------              5.3/7.6 MB 1.6 MB/s eta 0:00:02\n",
      "     ----------------------------             5.4/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ----------------------------             5.4/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ----------------------------             5.4/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ----------------------------             5.5/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ----------------------------             5.5/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -----------------------------            5.6/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -----------------------------            5.6/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -----------------------------            5.7/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -----------------------------            5.7/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ------------------------------           5.7/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ------------------------------           5.8/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ------------------------------           5.9/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     ------------------------------           5.9/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------          6.0/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------          6.0/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------          6.1/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     --------------------------------         6.2/7.6 MB 1.5 MB/s eta 0:00:02\n",
      "     --------------------------------         6.2/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------         6.3/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------------------         6.3/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.4/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.4/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.5/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.6/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.6/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      6.8/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      6.8/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.9/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.9/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.0/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.0/7.6 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.1/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.1/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.1/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.1/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.1/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.2/7.6 MB 1.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.4/7.6 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.6/7.6 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.6/7.6 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.6/7.6 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-win_amd64.whl (160 kB)\n",
      "                                              0.0/160.2 kB ? eta -:--:--\n",
      "     ---------                               41.0/160.2 kB 1.9 MB/s eta 0:00:01\n",
      "     --------------                          61.4/160.2 kB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------   153.6/160.2 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 160.2/160.2 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "     ----                                     0.1/1.0 MB 3.3 MB/s eta 0:00:01\n",
      "     ----                                     0.1/1.0 MB 3.6 MB/s eta 0:00:01\n",
      "     ---------                                0.2/1.0 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------                               0.3/1.0 MB 2.0 MB/s eta 0:00:01\n",
      "     --------------                           0.4/1.0 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------                           0.4/1.0 MB 1.6 MB/s eta 0:00:01\n",
      "     -----------------                        0.5/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "     --------------------                     0.5/1.0 MB 1.5 MB/s eta 0:00:01\n",
      "     ---------------------                    0.6/1.0 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------                 0.6/1.0 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------                0.6/1.0 MB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------             0.7/1.0 MB 1.4 MB/s eta 0:00:01\n",
      "     -----------------------------            0.7/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------          0.8/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "     --------------------------------         0.8/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------------------       0.9/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     0.9/1.0 MB 1.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     0.9/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------    1.0/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "                                              0.0/55.4 kB ? eta -:--:--\n",
      "     ----------------------                   30.7/55.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 55.4/55.4 kB 579.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.4 importlib-resources-5.12.0 kiwisolver-1.4.4 matplotlib-3.7.1\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 1.5466\n",
      "Valid Loss: 0.0139\n",
      "Perplexity: 1.01\n",
      "--------------------\n",
      "Epoch 2/10\n",
      "Train Loss: 0.0495\n",
      "Valid Loss: 0.0055\n",
      "Perplexity: 1.01\n",
      "--------------------\n",
      "Epoch 3/10\n",
      "Train Loss: 0.0297\n",
      "Valid Loss: 0.0018\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 4/10\n",
      "Train Loss: 0.0252\n",
      "Valid Loss: 0.0005\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 5/10\n",
      "Train Loss: 0.0196\n",
      "Valid Loss: 0.0003\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0225\n",
      "Valid Loss: 0.0001\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0198\n",
      "Valid Loss: 0.0001\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0176\n",
      "Valid Loss: 0.0001\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0197\n",
      "Valid Loss: 0.0000\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0197\n",
      "Valid Loss: 0.0000\n",
      "Perplexity: 1.00\n",
      "--------------------\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class MarketingDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            self.lines = [line.strip() for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokenizer.encode(self.lines[idx], add_special_tokens=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = MarketingDataset('text.txt', tokenizer)\n",
    "valid_dataset = MarketingDataset('valid.txt', tokenizer)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(item) for item in batch]\n",
    "    max_len = max(len(ids) for ids in input_ids)\n",
    "    padded_input_ids = torch.stack([torch.cat((ids, torch.zeros(max_len - len(ids), dtype=torch.long))) for ids in input_ids])\n",
    "    return padded_input_ids\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=5e-5)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch, labels=batch)\n",
    "        loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * batch.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch, labels=batch)\n",
    "            loss = criterion(output.logits.view(-1, output.logits.size(-1)), batch.view(-1))\n",
    "            valid_loss += loss.item() * batch.size(0)\n",
    "        valid_loss /= len(valid_dataset)\n",
    "        \n",
    "    perplexity = torch.exp(torch.tensor(valid_loss))\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model3.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "# Plotting the loss graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs+1), valid_losses, label='Valid Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\transformers\\modeling_utils.py:1719: UserWarning: `save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('D:/College/SEM VI/IPD/mark/this', save_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: Wrrite a subject line to review food was good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good good\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('D:/College/SEM VI/IPD/mark/this')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def generate_text(prompt, max_length=100):\n",
    "    input_ids = tokenizer.encode(prompt, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Write a subject line to review food was good\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
