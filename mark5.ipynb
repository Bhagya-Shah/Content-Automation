{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (4.28.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (pyproject.toml): started\n",
      "  Building wheel for pytorch (pyproject.toml): finished with status 'error'\n",
      "Failed to build pytorch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pytorch (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [17 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 251, in build_wheel\n",
      "          return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Temp\\pip-build-env-d8023cso\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 416, in build_wheel\n",
      "          return self._build_with_temp_dir(['bdist_wheel'], '.whl',\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Temp\\pip-build-env-d8023cso\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 401, in _build_with_temp_dir\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Temp\\pip-build-env-d8023cso\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 487, in run_setup\n",
      "          super(_BuildMetaLegacyBackend,\n",
      "        File \"C:\\Users\\91932\\AppData\\Local\\Temp\\pip-build-env-d8023cso\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 338, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 15, in <module>\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "ERROR: Could not build wheels for pytorch, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Load the sentiment-response dataset\n",
    "df = pd.read_excel('result.xlsx')\n",
    "sentiments = df['sentiment'].tolist()\n",
    "responses = df['response'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GPT-3 model and tokenizer\n",
    "generator = pipeline('text-generation', model='GPT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('GPT2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Encode the sentiments and responses using the tokenizer\n",
    "# input_ids = tokenizer(sentiments, responses, truncation=True, padding=True)\n",
    "\n",
    "# Loop over the dataset and generate email responses\n",
    "generated_responses = []\n",
    "for i in range(1):\n",
    "    # Generate a response from the model\n",
    "    response = generator(responses[i], max_length=512, do_sample=True, top_k=50)[0]['generated_text']\n",
    "    generated_responses.append(response)\n",
    "\n",
    "# Compute the BLEU score between the generated and true responses\n",
    "# bleu_scores = []\n",
    "# for generated_response, true_response in zip(generated_responses, responses):\n",
    "#     generated_tokens = tokenizer.tokenize(generated_response)\n",
    "#     true_tokens = tokenizer.tokenize(true_response)\n",
    "#     bleu_score = sentence_bleu([true_tokens], generated_tokens)\n",
    "#     bleu_scores.append(bleu_score)\n",
    "\n",
    "# print(f\"Average BLEU score: {np.mean(bleu_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subject: Satisfy your cravings with our delicious desserts!  Dear [Recipient],  Are you in the mood for something sweet and indulgent? Our bakery offers a wide range of mouth-watering desserts that are sure to satisfy your cravings. From classic favorites like chocolate cake to exotic treats like macarons, we have something for everyone. Order now and treat yourself to the best desserts in town!  Best regards,  [Your Name]  Subject: Spice up your meals with our gourmet sauces!  Dear [Recipient],  Are you in the mood to add some zest and spice to your meals? Our deliciously flavored sauces are always a hit and can be used from soups and stews to sauces, salads, or even in the kitchen. Choose from our many varieties like Basted Chicken, BBQ Pork, BBQ Ranch, or Garlic Sauce. Order now and enjoy! [Your Name]  \\n---\\nTo whom it may concern:\\nI am writing to you because our gourmet sauces are the perfect example of how delicious and satisfying it is to be indulged in something nice and tasty. We are a locally owned and operated restaurant and bakery specializing in the sale of healthy, fresh-made salads, baked goods, deli items, and frozen entrees. We also offer a large selection of gourmet sauces, dressings, and condiments in our store. Our gourmet sauces and dressings are sold in a variety of flavors as well as in the raw, chopped, and blended forms. Our menu items cater to a wide variety of tastes and palates. We look forward to your business, and continue our great tasting product and service. We take pride in being your best choice as a supplier of gourmet sauces, dressings, and condiments in the South Bay.\\n\"I am a single woman, and have been single for nine years. I have a little boy my daughter is so excited to be a part of the family. I also have a little dog. Since moving to the Bay Area and living on the east side, I have experienced what can be referred to as the \"spice box\" life. But, I don\\'t get high/highs nor do I get high on the regular. I enjoy a variety of food including my favorite - hot chocolates. I also get high on the regular. But I don\\'t get high on the regular.\\nI also get high on the regular. But I don\\'t get high on the regular']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "                                              0.0/8.4 MB ? eta -:--:--\n",
      "                                              0.0/8.4 MB 1.3 MB/s eta 0:00:07\n",
      "                                              0.1/8.4 MB 1.3 MB/s eta 0:00:07\n",
      "                                              0.2/8.4 MB 1.4 MB/s eta 0:00:06\n",
      "                                              0.2/8.4 MB 1.4 MB/s eta 0:00:06\n",
      "     --                                       0.4/8.4 MB 1.7 MB/s eta 0:00:05\n",
      "     --                                       0.5/8.4 MB 1.7 MB/s eta 0:00:05\n",
      "     --                                       0.6/8.4 MB 1.8 MB/s eta 0:00:05\n",
      "     ---                                      0.7/8.4 MB 1.9 MB/s eta 0:00:05\n",
      "     ---                                      0.8/8.4 MB 1.8 MB/s eta 0:00:05\n",
      "     ----                                     0.9/8.4 MB 1.9 MB/s eta 0:00:04\n",
      "     ----                                     1.0/8.4 MB 2.0 MB/s eta 0:00:04\n",
      "     -----                                    1.1/8.4 MB 2.0 MB/s eta 0:00:04\n",
      "     ------                                   1.3/8.4 MB 2.1 MB/s eta 0:00:04\n",
      "     ------                                   1.4/8.4 MB 2.1 MB/s eta 0:00:04\n",
      "     -------                                  1.5/8.4 MB 2.1 MB/s eta 0:00:04\n",
      "     -------                                  1.6/8.4 MB 2.1 MB/s eta 0:00:04\n",
      "     --------                                 1.7/8.4 MB 2.2 MB/s eta 0:00:04\n",
      "     --------                                 1.8/8.4 MB 2.2 MB/s eta 0:00:04\n",
      "     ---------                                2.0/8.4 MB 2.2 MB/s eta 0:00:03\n",
      "     ----------                               2.2/8.4 MB 2.3 MB/s eta 0:00:03\n",
      "     -----------                              2.4/8.4 MB 2.4 MB/s eta 0:00:03\n",
      "     -----------                              2.4/8.4 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------                             2.5/8.4 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------                             2.6/8.4 MB 2.3 MB/s eta 0:00:03\n",
      "     ------------                             2.7/8.4 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------                            2.8/8.4 MB 2.2 MB/s eta 0:00:03\n",
      "     -------------                            2.9/8.4 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------                           2.9/8.4 MB 2.2 MB/s eta 0:00:03\n",
      "     --------------                           3.0/8.4 MB 2.1 MB/s eta 0:00:03\n",
      "     --------------                           3.1/8.4 MB 2.1 MB/s eta 0:00:03\n",
      "     --------------                           3.1/8.4 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------                          3.1/8.4 MB 2.1 MB/s eta 0:00:03\n",
      "     ---------------                          3.2/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     ---------------                          3.3/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     ----------------                         3.4/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     ----------------                         3.5/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     ----------------                         3.5/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     -----------------                        3.6/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     -----------------                        3.7/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     ------------------                       3.8/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     ------------------                       3.9/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     ------------------                       4.0/8.4 MB 2.0 MB/s eta 0:00:03\n",
      "     -------------------                      4.0/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     -------------------                      4.1/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     -------------------                      4.1/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     --------------------                     4.2/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     --------------------                     4.3/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     --------------------                     4.4/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     ---------------------                    4.5/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     ---------------------                    4.6/8.4 MB 1.9 MB/s eta 0:00:03\n",
      "     ----------------------                   4.6/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     ----------------------                   4.8/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     -----------------------                  4.8/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     -----------------------                  4.9/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     -----------------------                  5.0/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------                 5.1/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------                 5.1/8.4 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------------------                 5.2/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     ------------------------                 5.2/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------                5.2/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------                5.3/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------                5.3/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     -------------------------                5.4/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------------               5.4/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------------               5.5/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------------               5.6/8.4 MB 1.8 MB/s eta 0:00:02\n",
      "     --------------------------               5.6/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------              5.7/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------              5.7/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------              5.8/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ---------------------------              5.8/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------             5.9/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------             5.9/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------             5.9/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------------------------             6.0/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     -----------------------------            6.1/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     -----------------------------            6.1/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     -----------------------------            6.2/8.4 MB 1.7 MB/s eta 0:00:02\n",
      "     -----------------------------            6.2/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     ------------------------------           6.3/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     ------------------------------           6.4/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     ------------------------------           6.4/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     ------------------------------           6.5/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     -------------------------------          6.6/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     -------------------------------          6.6/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     -------------------------------          6.7/8.4 MB 1.6 MB/s eta 0:00:02\n",
      "     --------------------------------         6.8/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------         6.8/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------         6.9/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.9/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        7.0/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        7.0/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        7.1/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       7.2/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       7.2/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       7.2/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.3/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.4/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.5/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      7.5/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.6/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.7/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     7.7/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.8/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.9/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------------   8.0/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------------   8.0/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------------   8.2/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.3/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.4/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  8.4/8.4 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 8.4/8.4 MB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn) (1.23.5)\n",
      "Collecting scipy>=1.3.2 (from scikit-learn)\n",
      "  Using cached scipy-1.10.1-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn) (1.2.0)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (3.8.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: click in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91932\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in 'C:\\\\Users\\\\91932\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.18611086836903165\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.17840650392339336\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel('result.xlsx')\n",
    "\n",
    "# Preprocess data\n",
    "data['response'] = data['response'].apply(lambda x: x.lower())\n",
    "data['response'] = data['response'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data = data[:50]\n",
    "test_data = data[50:]\n",
    "\n",
    "# Build sentiment analysis model\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['response'])\n",
    "y_train = train_data['sentiment']\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract keywords from review text\n",
    "review_text = 'The product was great and the service was excellent'\n",
    "review_text = review_text.lower()\n",
    "review_text = ' '.join([word for word in review_text.split() if word not in stopwords.words('english')])\n",
    "review_keywords = vectorizer.transform([review_text])\n",
    "\n",
    "# Make prediction using model\n",
    "prediction = model.predict(review_keywords)[0]\n",
    "print(prediction)\n",
    "\n",
    "# Find suitable email response based on prediction and keywords\n",
    "suitable_response = ''\n",
    "for index, row in data.iterrows():\n",
    "    if row['sentiment'] == prediction:\n",
    "        response_keywords = vectorizer.transform([row['response']])\n",
    "        similarity_score = (review_keywords * response_keywords.T).A[0][0]\n",
    "        print(similarity_score)\n",
    "        if similarity_score > 0.5:\n",
    "            print(\"there\")\n",
    "            suitable_response = row['response']\n",
    "            break\n",
    "\n",
    "# Print suitable email response\n",
    "print(suitable_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suitable_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel('result.xlsx')\n",
    "\n",
    "# Preprocess data\n",
    "data['response'] = data['response'].apply(lambda x: x.lower())\n",
    "data['response'] = data['response'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "# Split data into positive and negative subsets\n",
    "positive_data = data[data['sentiment'] == 'positive']\n",
    "negative_data = data[data['sentiment'] == 'negative']\n",
    "\n",
    "# Build sentiment analysis models\n",
    "vectorizer_pos = TfidfVectorizer()\n",
    "X_train_pos = vectorizer_pos.fit_transform(positive_data['response'])\n",
    "y_train_pos = positive_data['sentiment']\n",
    "model_pos = LogisticRegression()\n",
    "model_pos.fit(X_train_pos, y_train_pos)\n",
    "\n",
    "vectorizer_neg = TfidfVectorizer()\n",
    "X_train_neg = vectorizer_neg.fit_transform(negative_data['response'])\n",
    "y_train_neg = negative_data['sentiment']\n",
    "model_neg = LogisticRegression()\n",
    "model_neg.fit(X_train_neg, y_train_neg)\n",
    "\n",
    "# Extract keywords from review response\n",
    "review_text = 'The product was great and the service was excellent'\n",
    "review_text = review_text.lower()\n",
    "review_text = ' '.join([word for word in review_text.split() if word not in stopwords.words('english')])\n",
    "review_keywords = vectorizer_pos.transform([review_text])\n",
    "\n",
    "# Make prediction using appropriate model based on review sentiment\n",
    "if model_pos.predict(review_keywords)[0] == 'positive':\n",
    "    suitable_responses = positive_data\n",
    "    vectorizer = vectorizer_pos\n",
    "else:\n",
    "    suitable_responses = negative_data\n",
    "    vectorizer = vectorizer_neg\n",
    "\n",
    "# Find suitable email response based on keywords\n",
    "response_keywords = vectorizer.transform(suitable_responses['response'])\n",
    "similarity_scores = (review_keywords * response_keywords.T).A.ravel()\n",
    "most_similar_index = similarity_scores.argmax()\n",
    "suitable_response = suitable_responses.iloc[most_similar_index]['response']\n",
    "\n",
    "# Print suitable email response\n",
    "print(suitable_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91932\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: satisfy cravings delicious desserts! dear [recipient], mood something sweet indulgent? bakery offers wide range mouth-watering desserts sure satisfy cravings. classic favorites like chocolate cake exotic treats like macarons, something everyone. order treat best desserts town! best regards, [your name] subject: spice meals gourmet sauces!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_excel('result.xlsx')\n",
    "\n",
    "# Preprocess data\n",
    "data['response'] = data['response'].apply(lambda x: x.lower())\n",
    "data['response'] = data['response'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "# Extract keywords from review\n",
    "review_text = \"Food was excellent If you're in the mood for something sweet\"\n",
    "review_text = review_text.lower()\n",
    "review_text = ' '.join([word for word in review_text.split() if word not in stopwords.words('english')])\n",
    "review_keywords = set(review_text.split())\n",
    "\n",
    "# Select subset of data based on sentiment\n",
    "sentiment = 'positive'\n",
    "data_subset = data[data['sentiment'] == sentiment]\n",
    "\n",
    "# Find best matching response\n",
    "response = None\n",
    "max_score = -1\n",
    "for _, row in data_subset.iterrows():\n",
    "    response_text = row['response'].lower()\n",
    "    response_keywords = set(response_text.split())\n",
    "    score = len(review_keywords.intersection(response_keywords))\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        response = row['response']\n",
    "\n",
    "# Print best matching response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91932\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from perplexity import calper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Perplexity Score : 311.748'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calper(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
